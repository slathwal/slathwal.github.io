[
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "Posts",
    "section": "",
    "text": "Diabetes prevalence in Community Health Survey Data 2019-2020 in Canada\n\n\n\n\n\nDiabetes prevalence varies significantly across provinces and territories.\n\n\n\n\n\nMay 13, 2025\n\n\nShefali Lathwal\n\n\n2 min\n\n\n339 words\n\n\n\n\n\n\n\n\n\n\n\n\nChance, p-values, and number of samples\n\n\n\n\n\nIntuition is not always reliable.\n\n\n\n\n\nApr 17, 2025\n\n\nShefali Lathwal\n\n\n5 min\n\n\n929 words\n\n\n\n\n\n\n\n\n\n\n\n\nPermutation test in statistics\n\n\n\n\n\nIf you want to compare median value of two different groups in a training dataset, which statistical test will you use? If you do not know the answer, permutation test will come in handy.\n\n\n\n\n\nMar 27, 2025\n\n\nShefali Lathwal\n\n\n8 min\n\n\n1,420 words\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Home",
    "section": "",
    "text": "The PDAC-app is an interactive application that allows users to explore the pancreatic cancer data available from TCGA.\nYou can look at the overall demographic distribution of the patients, Kaplan Meier survival plots broken by clinical characteristics, and an analysis of tumor purity and molecular clusters in the data based on the article Integrated Genomics Characterization of Pancreatic Ductal Adenocarcinoma.\nYou can interact with the data in the shiny app here."
  },
  {
    "objectID": "projects.html#analysis-of-clinical-and-molecular-data-for-pancreatic-cancer-from-the-cancer-genome-atlas-tcga",
    "href": "projects.html#analysis-of-clinical-and-molecular-data-for-pancreatic-cancer-from-the-cancer-genome-atlas-tcga",
    "title": "Home",
    "section": "",
    "text": "The PDAC-app is an interactive application that allows users to explore the pancreatic cancer data available from TCGA.\nYou can look at the overall demographic distribution of the patients, Kaplan Meier survival plots broken by clinical characteristics, and an analysis of tumor purity and molecular clusters in the data based on the article Integrated Genomics Characterization of Pancreatic Ductal Adenocarcinoma.\nYou can interact with the data in the shiny app here."
  },
  {
    "objectID": "projects.html#analysis-of-political-donations-through-electoral-bonds-in-india",
    "href": "projects.html#analysis-of-political-donations-through-electoral-bonds-in-india",
    "title": "Home",
    "section": "Analysis of political donations through electoral bonds in India",
    "text": "Analysis of political donations through electoral bonds in India\n\n\n\nThis web application was created as the final project for Harvard’s course, CS50: Introduction to Computer Science. The following tools were used:\n\nPython for extracting the data from pdf to csv format\nR for data exploration and cleaning\nRShiny for data analysis and visualization.\nBootstrap library for R (bslib) to design a multi-page Shiny app"
  },
  {
    "objectID": "background.html",
    "href": "background.html",
    "title": "Background",
    "section": "",
    "text": "I am a MIT-trained Ph.D. with interest in statistics, data science, biology, data visualizations, education, watercolour, sketching, and many more things.\n\n\n\n Back to top"
  },
  {
    "objectID": "blogs/2025-03-27/index.html",
    "href": "blogs/2025-03-27/index.html",
    "title": "Permutation test in statistics",
    "section": "",
    "text": "Permutation is a technique in statistics that allows you to perform hypothesis testing using any measurement of interest. The steps are as follows:\nThe permuation algorithm is generic and can be used for any measurement. The idea is to compare an effect observed in the training data with a distribution generated by assuming that there is no effect in the data and calculate a p-value to determine the statistical significance of the effect. The permutation test does not involve making any assumptions about the distribution, and can therefore be used for quantities such as median and mode, for which no standard statistical tests exist.\nLet’s look at an example of how to perform permutation test."
  },
  {
    "objectID": "blogs/2025-03-27/index.html#look-at-the-number-of-people-born-in-each-century-after-the-year-1000",
    "href": "blogs/2025-03-27/index.html#look-at-the-number-of-people-born-in-each-century-after-the-year-1000",
    "title": "Permutation test in statistics",
    "section": "Look at the number of people born in each century after the year 1000",
    "text": "Look at the number of people born in each century after the year 1000\n\n# Create a new column called Century\ncenturies = np.arange(1000, 2100, 100)\ndf = age1.copy()\nfor century in centuries:\n    if century &gt;= 2000:\n        label = f\"{int(century/100) + 1}st century\"\n    else:\n        label = f\"{int(century/100) + 1}th century\"\n    df.loc[(df[\"Birth year\"] &gt;= century) & (df[\"Birth year\"] &lt; century+100), \"century\"] = label\ndf[\"century\"].value_counts()\n\ncentury\n20th century    93651\n19th century    90686\n18th century    22699\n17th century     9894\n16th century     7491\n15th century     4135\n14th century     2129\n13th century     1843\n12th century     1488\n11th century      983\n21st century       37\nName: count, dtype: int64\n\n\nWe can now look to see if there is a difference in Age of death between genders across different centuries."
  },
  {
    "objectID": "blogs/2025-03-27/index.html#look-at-the-median-difference-between-genders-across-centuries",
    "href": "blogs/2025-03-27/index.html#look-at-the-median-difference-between-genders-across-centuries",
    "title": "Permutation test in statistics",
    "section": "Look at the median difference between genders across centuries",
    "text": "Look at the median difference between genders across centuries\n\ndf[[\"Gender\", \"century\", \"Age of death\"]].groupby([\"century\", \"Gender\"])[\"Age of death\"].median()\n\ncentury       Gender\n11th century  Female    51.0\n              Male      56.0\n12th century  Female    50.5\n              Male      56.0\n13th century  Female    47.0\n              Male      56.0\n14th century  Female    46.0\n              Male      57.0\n15th century  Female    51.0\n              Male      60.0\n16th century  Female    55.0\n              Male      60.0\n17th century  Female    59.0\n              Male      64.0\n18th century  Female    64.0\n              Male      69.0\n19th century  Female    76.0\n              Male      72.0\n20th century  Female    78.0\n              Male      76.0\n21st century  Female    18.0\n              Male      17.0\nName: Age of death, dtype: float64\n\n\nWe can see that there are differences in median value of Age of death between the genders across centuries."
  },
  {
    "objectID": "blogs/2025-03-27/index.html#look-at-the-total-individuals-in-the-data-split-by-gender-across-centuries",
    "href": "blogs/2025-03-27/index.html#look-at-the-total-individuals-in-the-data-split-by-gender-across-centuries",
    "title": "Permutation test in statistics",
    "section": "Look at the total individuals in the data split by gender across centuries",
    "text": "Look at the total individuals in the data split by gender across centuries\n\ndf[[\"Gender\", \"century\", \"Age of death\"]].groupby([\"century\"])[\"Gender\"].value_counts()\n\ncentury       Gender\n11th century  Male        864\n              Female      119\n12th century  Male       1300\n              Female      188\n13th century  Male       1566\n              Female      277\n14th century  Male       1828\n              Female      301\n15th century  Male       3743\n              Female      392\n16th century  Male       6912\n              Female      579\n17th century  Male       9186\n              Female      708\n18th century  Male      21406\n              Female     1293\n19th century  Male      84258\n              Female     6428\n20th century  Male      83259\n              Female    10392\n21st century  Male         28\n              Female        9\nName: count, dtype: int64\n\n\nFor the permutation test, we will pick a century and test if the median difference in Age of Death between genders is statistically significant or not. We can pick data from any century, but for the following analysis, we will focus on the 13th century."
  },
  {
    "objectID": "blogs/2025-03-27/index.html#calculate-the-difference-between-median-age-of-death-of-genders-in-the-data",
    "href": "blogs/2025-03-27/index.html#calculate-the-difference-between-median-age-of-death-of-genders-in-the-data",
    "title": "Permutation test in statistics",
    "section": "Calculate the difference between median Age of death of genders in the data",
    "text": "Calculate the difference between median Age of death of genders in the data\n\n# Define a function to calculate the statistic of interest\ndef calculate_median_diff_genders(df):\n    median_diff_genders = (df[df[\"Gender\"]== \"Male\"][\"Age of death\"].median()) - (df[df[\"Gender\"]== \"Female\"][\"Age of death\"].median())\n    return median_diff_genders\n\nobserved_median_diff_genders = calculate_median_diff_genders(df_thirteen)\nobserved_median_diff_genders\n\n9.0"
  },
  {
    "objectID": "blogs/2025-03-27/index.html#shuffle-the-data-1000-times-and-create-a-distribution-of-difference-between-median-age-of-death-of-genders",
    "href": "blogs/2025-03-27/index.html#shuffle-the-data-1000-times-and-create-a-distribution-of-difference-between-median-age-of-death-of-genders",
    "title": "Permutation test in statistics",
    "section": "Shuffle the data 1000 times and create a distribution of difference between median Age of death of genders",
    "text": "Shuffle the data 1000 times and create a distribution of difference between median Age of death of genders\n\nn = 1000\nmedian_diff_genders_distribution = np.zeros(n)\nfor i in range(n):\n    shuffled_age = df_thirteen[\"Age of death\"].sample(df_thirteen.shape[0], replace = False).reset_index(drop = True)\n    df_shuffled = pd.DataFrame({\"Gender\": df_thirteen[\"Gender\"], \"Age of death\": shuffled_age})\n    median_diff_genders_distribution[i] = calculate_median_diff_genders(df_shuffled)"
  },
  {
    "objectID": "blogs/2025-03-27/index.html#calculate-95-confidence-intervals-for-observing-the-effect-of-gender-of-difference-in-median-value-of-age-of-death.",
    "href": "blogs/2025-03-27/index.html#calculate-95-confidence-intervals-for-observing-the-effect-of-gender-of-difference-in-median-value-of-age-of-death.",
    "title": "Permutation test in statistics",
    "section": "Calculate 95% confidence intervals for observing the effect of gender of difference in median value of Age of death.",
    "text": "Calculate 95% confidence intervals for observing the effect of gender of difference in median value of Age of death.\n\n# Calcualte 95% confidence interval\nmedian_diff_genders_distribution.sort()\nleft_value = median_diff_genders_distribution[int(2.5/100*n)]\nright_value = median_diff_genders_distribution[int(97.5/100*n)]\nleft_value, right_value\n\n(-3.0, 4.0)"
  },
  {
    "objectID": "blogs/2025-03-27/index.html#calculate-the-p-value-for-the-observed-difference-in-median-of-age-of-death-between-genders",
    "href": "blogs/2025-03-27/index.html#calculate-the-p-value-for-the-observed-difference-in-median-of-age-of-death-between-genders",
    "title": "Permutation test in statistics",
    "section": "Calculate the p-value for the observed difference in median of Age of death between genders",
    "text": "Calculate the p-value for the observed difference in median of Age of death between genders\n\np_value = np.sum((median_diff_genders_distribution &lt; -abs(observed_median_diff_genders)) | (median_diff_genders_distribution &gt; abs(observed_median_diff_genders)))/n*100\np_value\n\n0.0"
  },
  {
    "objectID": "blogs/2025-03-27/index.html#plot-the-observed-statistic-with-the-obtained-distribution-and-95-confidence-intervals",
    "href": "blogs/2025-03-27/index.html#plot-the-observed-statistic-with-the-obtained-distribution-and-95-confidence-intervals",
    "title": "Permutation test in statistics",
    "section": "Plot the observed statistic with the obtained distribution and 95% confidence intervals",
    "text": "Plot the observed statistic with the obtained distribution and 95% confidence intervals\n\nsns.histplot(median_diff_genders_distribution, discrete = True)\nplt.axvline(x = left_value, c = \"red\", ls = \"--\", label = \"95% confidence interval\")\nplt.axvline(x = right_value, c = \"red\", ls = \"--\")\nplt. axvline(x = observed_median_diff_genders, c = \"blue\", lw = 2, label = \"observed value in the data\")\nplt.legend(loc = \"upper left\")\nplt.xlabel(\"Median age of death (Male) - Median age of death (Female)\");\n\n\n\n\n\n\n\nFigure 3: Comparison of observed statistic with distribution generated under null hypothesis. The left and right limits for 95% confidence interval are marked as dashed red lines. The actual value of the statistic (difference in median value of Age of death between males and females) is marked by the solid black line."
  },
  {
    "objectID": "blogs/2025-03-27/index.html#footnotes",
    "href": "blogs/2025-03-27/index.html#footnotes",
    "title": "Permutation test in statistics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n Amoradnejad, Issa; Amoradnejad, Rahimberdi; et al. (2022). “Age dataset: A structured general-purpose dataset on life, work, and death of 1.22 million distinguished people”. Workshop Proceedings of the 16th International AAAI Conference on Web and Social Media (ICWSM). 3. ICWSM: 1–4. doi:10.36190/2022.82.↩︎"
  },
  {
    "objectID": "blogs/2025-04-17/index.html",
    "href": "blogs/2025-04-17/index.html",
    "title": "Chance, p-values, and number of samples",
    "section": "",
    "text": "Problem Statement\n\nTake two exactly equal Gaussian distributions.\nDraw 3, 6, 10, 25, 50, and 100 random samples from each distribution 1000 times.\nPerform a t-test to check whether the sample means are significantly different from each other, with a p-value threshold of 0.05.\nWill the % of times p-value is less than 0.05, i.e., you reject the null hypothesis that the samples come from the same distribution, change with the number of samples drawn? If yes, will it increase or decrease with increasing number of samples?\n\nMy initial instinct is to say, “The chance of concluding that the samples come from two different populations should decrease with increasing number of samples. After all, the more samples we have, the less the chance of making a mistake.”\nLet’s test our intuition.\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport scipy.stats as stats\nimport matplotlib.animation as animation\nfrom IPython.display import HTML\nfrom functools import partial\n\n\n\nTake two exactly equal Gaussian distributions\n\nx = np.linspace(-10,10,100)\ny1 = stats.norm.pdf(x, loc = 0, scale = 2) # Normal distribution with mean=0, and standard deviation = 2\ny2 = stats.norm.pdf(x, loc = 0, scale = 2) # Second normal distribution with mean = 0, standard deviation = 2\n\n# Plot the two distributions\nfig, (ax1, ax2) = plt.subplots(1,2, layout = \"constrained\", sharey=True)\nax1.plot(x, y1, label = \"Population 1\", c = \"blue\")\nax1.set_xlabel(\"\")\nax1.set_ylabel(\"Probability\")\nax1. set_title(\"Population 1\")\nax2.plot(x, y2, label = \"Population 2\", c = \"red\")\nax2.set_xlabel(\"\")\n#ax2.set_ylabel(\"Probability\")\nax2. set_title(\"Population 2\");\n\n\n\n\n\n\n\n\n\n\nDraw random samples and check if sample means are significantly different\n\nn_trials = 1000\nn_samples = np.array([3,6,10,25,50,100,150, 200,350, 500, 750, 1000, 1250, 1500, 1750 ,2000])\nsignificance_threshold = 0.05\n\nrng = np.random.default_rng(seed = 42)\n\ndef test_significant_difference(sample1, sample2):\n    tstatistic, pvalue = stats.ttest_ind(sample1, sample2, equal_var = True)\n    return (tstatistic, pvalue)\n\ndef compare_two_randomly_drawn_samples(n_samples, significance_threshold):\n    sample1 = rng.normal(loc = 0, scale = 2, size = n_samples) # Draw random samples from 1st population\n    sample2 = rng.normal(loc = 0, scale = 2, size = n_samples) # Draw random samples from 2nd population\n    tstatistic, pvalue = test_significant_difference(sample1, sample2)\n    significance = False\n    if (pvalue &lt; significance_threshold):\n        significance = True\n    return (pvalue, significance, tstatistic)\n\ndef significant_results(n_samples, significance_threshold, n_trials):\n    pvalue_list = []\n    significance_list = []\n    tstatistic_list = []\n    for trial in range(n_trials):\n        pvalue, significance, tstatistic = compare_two_randomly_drawn_samples(n_samples, significance_threshold)\n        \n        pvalue_list.append(pvalue)\n        significance_list.append(significance)\n        tstatistic_list.append(tstatistic)\n\n\n    #fig, ax = plt.subplots(layout = \"constrained\")\n    #ax.hist(tstatistic_list, bins = 50, density = True)\n    #ax.axvline(x = 0.05, c= \"red\", ls = \"--\")\n    #ax.set_xlabel(\"p-value\")\n    #ax.set_xlabel(\"t-statistic\")\n    #ax.set_ylabel(\"Percentage of samples\")\n    #ax.set_title(f\"Number of samples: {n_samples}\")\n\n    return pvalue_list, significance_list\n    \n    \n    \n# Run the above for different sample sizes\n\npercentage_significant_list = []\nfor samples in n_samples:\n    #print(samples)\n    pvalue_list, significance_list = significant_results(samples,significance_threshold, n_trials)\n    percentage_significant_list.append(sum(significance_list)/len(significance_list)*100)\n    \nresults_df = pd.DataFrame({\"samples\": n_samples, \"percentage_significant\": percentage_significant_list})\nresults_df\n\n\n\n\n\n\n\n\nsamples\npercentage_significant\n\n\n\n\n0\n3\n4.3\n\n\n1\n6\n5.4\n\n\n2\n10\n5.0\n\n\n3\n25\n4.7\n\n\n4\n50\n4.5\n\n\n5\n100\n5.3\n\n\n6\n150\n4.6\n\n\n7\n200\n5.0\n\n\n8\n350\n5.4\n\n\n9\n500\n7.0\n\n\n10\n750\n4.4\n\n\n11\n1000\n6.1\n\n\n12\n1250\n4.5\n\n\n13\n1500\n4.0\n\n\n14\n1750\n5.5\n\n\n15\n2000\n5.0\n\n\n\n\n\n\n\nThe dataframe tabulates the percentage of times we conclude that the samples are drawn from different populations for different number of samples drawn from the population.\n\n\nCompare the chance of rejecting the null hypothesis with increasing number of samples\n\nfig, ax = plt.subplots()\nresults_df.plot(x = \"samples\", y = \"percentage_significant\", style = \"o\", ax = ax, ylim = (0,10))\nax.axhline(y = 5, c = \"red\", ls = \"--\")\nax.set_ylabel(\"Percentage of trials where we reject null hypothesis\");\n\n\n\n\n\n\n\n\n\n\nConclusion\nThe results show that our intuition is incorrect. As number of samples increase, the percentage of trials where we will conclude that samples come from two different populations stays constant at about 5%. This is because p-value actually defines the probability of rejecting the null hypothesis incorrectly. So, if we have a significance threshold of 0.05, there is a 5% chance that we will incorrectly reject the null hypothesis. This chance remains the same, irrespective of the number of samples drawn.\n\n\nAnimate random sampling\nLet’s visualize one of the cases with an animation.\n\nn_trials = 100\nn_samples = 10\n\n# Generate the figure\nfig, ax = plt.subplots(layout = \"constrained\")\nline1, = ax.plot(x, y1, c = \"blue\")\nax.set_ylabel(\"Probability\")\nline2, = ax.plot(x, y2+0.001, c = \"red\")\n\nscat1 = ax.scatter(rng.normal(loc = 0, scale = 2, size = n_samples), 0.05*np.ones(n_samples), c = \"blue\", s = 100, alpha = 0.6, label = \"Sample 1\")\nscat2 = ax.scatter(rng.normal(loc = 0, scale = 2, size = n_samples), 0.05*np.ones(n_samples), c = \"red\", s = 100, alpha = 0.6, label = \"Sample 2\")\nax.set_xlim((-10, 10))\ntext = ax.text(x = 0, y = 0.06, s = \"\", horizontalalignment='center', verticalalignment='center')\nax.legend()\n\ndef update(frame):\n    tempx1 = rng.normal(loc = 0, scale = 1, size = n_samples)\n    tempy1 = 0.03*np.ones(n_samples)\n    data1 = np.stack([tempx1, tempy1], axis = 1)\n    scat1.set_offsets(data1)\n    tempx2 = rng.normal(loc = 0, scale = 1, size = n_samples)\n    tempy2 = 0.02*np.ones(n_samples)\n    data2 = np.stack([tempx2, tempy2], axis = 1)\n    scat2.set_offsets(data2)\n    _, pvalue = test_significant_difference(tempx1, tempx2)\n    color = \"red\" if (pvalue &lt; significance_threshold) else \"green\"\n    significance = \"No difference\" if (pvalue &gt;= significance_threshold) else \"Significant difference\"\n    text.set_text(f\"trial:{frame+1}\\n pvalue = {pvalue:.3f}\\n Conclusion:\\n{significance}\")\n    text.set_color(color)\n    return(scat1, scat2)\n\n# Construct FuncAnimation Object\nani = animation.FuncAnimation(fig = fig, func = update, frames = 100, interval = 1000)\nani.save('animation_drawing.gif', writer='pillow');\nplt.close()\nHTML(ani.to_jshtml())\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\nNote: Click the forward arrow button to play the animation.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "blogs/2025-05-13/index.html",
    "href": "blogs/2025-05-13/index.html",
    "title": "Diabetes prevalence in Community Health Survey Data 2019-2020 in Canada",
    "section": "",
    "text": "Statistics Canada releases the results of a Community Health Survey for public use every 2 years. The latest data are available for the years 2019-2020. I downloaded these data in a csv format and analyzed them in python. The map is obtained from Government of Canada website and is from te 2016 Census.\nThe documentation provided by Statistics Canada is quite comprehensive and contains a data dictionary with an explanation of each field in the data. - Each row in the data is a survey respondent. - Each column is either a field directly answered by people, or grouped or derived from other fields. - The data are anonymized and de-identified. - the data for the three territories are grouped together.\n\nLoad the data\n\nimport pandas as pd\nimport numpy as np\n\ndf = pd.read_csv(\"./data/pumf_cchs.csv\")\ndf.head()\n\n\n\n\n\n\n\n\nADM_RNO1\nVERDATE\nREFPER\nGEOGPRV\nGEODGHR4\nDHH_SEX\nDHHGMS\nDHHDGHSZ\nADM_PRX\nDHHGAGE\n...\nFSCDVHF2\nINCG015\nINCDGHH\nINCDGRCA\nINCDGRPR\nINCDGRRS\nADM_040\nADM_045\nADM_050\nWTS_M\n\n\n\n\n0\n1000\n20240531\n2019-2020\n47.0\n47906.0\n2.0\n1.0\n2.0\n2.0\n3.0\n...\n0.0\n1.0\n5.0\n4.0\n4.0\n4.0\n1.0\n1.0\n6.0\n762.82\n\n\n1\n100005\n20240531\n2019-2020\n47.0\n47906.0\n1.0\n1.0\n2.0\n2.0\n5.0\n...\n0.0\n2.0\n4.0\n2.0\n2.0\n2.0\n6.0\n1.0\n6.0\n31.78\n\n\n2\n100012\n20240531\n2019-2020\n59.0\n59914.0\n2.0\n2.0\n1.0\n2.0\n5.0\n...\n6.0\n2.0\n2.0\n1.0\n1.0\n1.0\n2.0\n1.0\n6.0\n59.24\n\n\n3\n100015\n20240531\n2019-2020\n13.0\n13904.0\n1.0\n2.0\n1.0\n2.0\n5.0\n...\n0.0\n2.0\n3.0\n3.0\n3.0\n9.0\n6.0\n1.0\n6.0\n22.83\n\n\n4\n100018\n20240531\n2019-2020\n46.0\n46903.0\n1.0\n2.0\n1.0\n2.0\n4.0\n...\n0.0\n2.0\n1.0\n1.0\n1.0\n9.0\n2.0\n1.0\n6.0\n39.96\n\n\n\n\n5 rows × 691 columns\n\n\n\n\n\nExamine the size of the data\n\nprint(df.shape)\ncol_list = df.columns.tolist()\nprint(col_list)\n\n(108252, 691)\n['ADM_RNO1', 'VERDATE', 'REFPER', 'GEOGPRV', 'GEODGHR4', 'DHH_SEX', 'DHHGMS', 'DHHDGHSZ', 'ADM_PRX', 'DHHGAGE', 'DOMAC', 'MAC_010', 'EHG2DVH3', 'DOGEN', 'GEN_005', 'GEN_010', 'GEN_015', 'GEN_020', 'GEN_025', 'GEN_030', 'GENDVHDI', 'GENDVMHI', 'GENDVSWL', 'DOHWT', 'HWT_050', 'HWTDGISW', 'HWTDGWHO', 'HWTDGBCC', 'DOCCC', 'CCC_035', 'CCC_065', 'CCC_070', 'CCC_075', 'CCC_080', 'CCC_095', 'CCC_185', 'CCC_195', 'CCC_200', 'CCCDGRSP', 'CCCDGSKL', 'CCCDGCAR', 'DOHUI', 'HUIDGHSI', 'HUIDGPAD', 'DOCIH', 'CIH_005', 'CIH_010', 'CIH_015', 'CIH_020', 'CIH_025', 'CIH_030A', 'CIH_030B', 'CIH_030C', 'CIH_030D', 'CIH_030E', 'CIH_030F', 'CIH_030G', 'CIH_030H', 'CIH_030I', 'CIH_030J', 'CIH_030K', 'CIH_035', 'CIH_040A', 'CIH_040B', 'CIH_040C', 'CIH_040D', 'CIH_040E', 'CIH_040F', 'CIH_040G', 'CIH_040H', 'CIH_040I', 'DOFVC', 'FVCDVJUI', 'FVCDVFRU', 'FVCDVGRN', 'FVCDVORA', 'FVCDVPOT', 'FVCDVVEG', 'FVCDVTOT', 'FVCDVGDT', 'DOFGU', 'FGU_005', 'FGU_010', 'FGU_015A', 'FGU_015B', 'FGU_015C', 'FGU_015D', 'FGU_015E', 'FGU_015F', 'DOSMK', 'SMK_005', 'SMK_010', 'SMK_015', 'SMK_020', 'SMK_025', 'SMK_030', 'SMKG035', 'SMK_045', 'SMK_050', 'SMK_055', 'SMK_060', 'SMK_075', 'SMK_080', 'SMKG090', 'SMK_095', 'SMK_100', 'SMKG110', 'SMKDVSTY', 'SMKDGYCS', 'SMKDGSTP', 'DOTAL', 'TAL_005', 'TAL_010', 'TAL_015', 'TAL_020', 'TAL_025', 'TAL_030', 'TAL_035', 'TALDVUSE', 'DOETS', 'ETS_005', 'ETSG010', 'ETS_015', 'ETS_020', 'ETS_025A', 'ETS_025B', 'ETS_025C', 'ETS_025D', 'ETS_030', 'ETS_035', 'ETS_040', 'DOALC', 'ALC_005', 'ALC_010', 'ALC_015', 'ALC_020', 'ALCDVTTM', 'DOALW', 'ALW_005', 'ALW_010', 'ALW_015', 'ALW_020', 'ALW_025', 'ALW_030', 'ALW_035', 'ALW_040', 'ALWDVWKY', 'ALWDVDLY', 'ALWDVLTR', 'ALWDVSTR', 'DOAMU', 'AMU_005', 'AMU_010', 'AMU_015', 'AMU_020', 'AMU_025', 'AMU_030', 'AMU_040', 'AMU_045A', 'AMU_045B', 'AMU_045C', 'AMU_045D', 'AMU_045E', 'AMU_045F', 'DOCAN', 'CAN_015', 'CAN_030', 'CAN_035A', 'CAN_035B', 'CAN_035C', 'CAN_035D', 'CAN_035E', 'CAN_035F', 'CAN_035G', 'CAN_035H', 'CAN_035I', 'CAN_035J', 'CAN_040', 'CAN_045', 'CAN_050', 'CAN_055', 'DOSDS', 'SDS_005', 'SDS_010', 'SDS_015', 'SDS_020', 'SDS_025', 'SDSDVTOT', 'DODRG', 'DRGDVYA', 'DRGDVLA', 'DOPAA', 'PAA_005', 'PAA_010A', 'PAA_010B', 'PAA_010C', 'PAA_010D', 'PAA_010E', 'PAA_010F', 'PAA_010G', 'PAA_015', 'PAA_020', 'PAA_030', 'PAA_035', 'PAA_040A', 'PAA_040B', 'PAA_040C', 'PAA_040D', 'PAA_040E', 'PAA_040F', 'PAA_040G', 'PAA_045', 'PAA_050', 'PAA_060', 'PAA_065', 'PAA_070A', 'PAA_070B', 'PAA_070C', 'PAA_070D', 'PAA_070E', 'PAA_070F', 'PAA_070G', 'PAA_075', 'PAA_080', 'PAA_095', 'PAA_100', 'PAA_105', 'PAADVTRV', 'PAADVTRA', 'PAADVREC', 'PAADVRCA', 'PAADVOTH', 'PAADVOTA', 'PAADVMVA', 'PAADVACV', 'PAADVAC2', 'PAADVVIG', 'PAADVVOL', 'PAADVWHO', 'PAADVMON', 'PAADVTUE', 'PAADVWED', 'PAADVTHU', 'PAADVFRI', 'PAADVSAT', 'PAADVSUN', 'PAADVDYS', 'PAADVWKD', 'PAADVWND', 'DOPAY', 'PAY_005A', 'PAY_005B', 'PAY_005C', 'PAY_005D', 'PAY_010', 'PAY_025', 'PAY_030', 'PAY_045', 'PAY_050', 'PAY_065', 'PAY_070', 'PAY_090', 'PAY_095A', 'PAY_095B', 'PAY_095C', 'PAY_095D', 'PAY_095E', 'PAY_095F', 'PAY_095G', 'PAY_100', 'PAY_105', 'PAYDVTTR', 'PAYDVTSC', 'PAYDVADL', 'PAYDVTOA', 'PAYDVTMN', 'PAYDVTTU', 'PAYDVTWD', 'PAYDVTTH', 'PAYDVTFR', 'PAYDVTST', 'PAYDVTSN', 'PAYDVDYS', 'PAYDVMNS', 'PAYDVAV7', 'PAYDVTWK', 'PAYDVTWN', 'PAYDVDPG', 'PAYDVPAI', 'PAYDVVIG', 'PAYDVWK1', 'PAYDVWK2', 'PAYDVWK3', 'PAYDVPAG', 'DOSBE', 'SBE_005', 'SBE_010', 'DOSXB', 'SXB_005', 'SXB_080', 'SXB_095A', 'SXB_095B', 'SXB_095C', 'SXB_095D', 'SXB_095E', 'SXB_095F', 'SXB_095G', 'SXB_095H', 'SXB_095I', 'SXB_095J', 'SXB_095K', 'SXB_095L', 'SXB_150', 'DODRV', 'DRV_005', 'DRV_010', 'DRV_015', 'DRV_020', 'DRV_025', 'DRV_030', 'DRV_035', 'DRV_070', 'DRV_075', 'DODWI', 'DWI_005', 'DWI_010', 'DWI_015', 'DWI_020', 'DWI_025', 'DWI_030', 'DOFLU', 'FLU_005', 'FLU_010', 'FLU_015', 'FLU_020', 'FLU_025A', 'FLU_025B', 'FLU_025C', 'FLU_025D', 'FLU_025E', 'FLU_025F', 'FLU_025G', 'FLU_025H', 'FLU_025I', 'FLU_025J', 'FLU_025K', 'DOBPC', 'BPC_005', 'BPC_010', 'BPC_015B', 'BPC_015C', 'BPC_015D', 'BPC_015E', 'BPCG015F', 'BPC_020', 'DOMAM', 'MAM_005', 'MAM_010', 'MAM_013A', 'MAM_013B', 'MAM_013C', 'MAM_013D', 'MAM_013E', 'MAM_013F', 'MAM_013G', 'MAM_013H', 'MAM_015A', 'MAM_015B', 'MAM_015C', 'MAM_015D', 'MAM_015E', 'MAM_015F', 'MAM_015G', 'MAM_025', 'DOCCT', 'CCT_005', 'CCT_010', 'CCT_015A', 'CCT_015B', 'CCT_015C', 'CCT_015D', 'CCT_015E', 'CCT_015F', 'CCT_015G', 'CCT_015H', 'CCT_015I', 'CCT_020', 'CCT_025', 'CCT_030A', 'CCT_030B', 'CCT_030C', 'CCT_030D', 'CCT_030E', 'CCT_030F', 'CCT_030G', 'CCT_030H', 'CCT_030I', 'CCT_035', 'CCT_040', 'CCT_045C', 'CCT_045D', 'CCT_045G', 'CCT_045H', 'CCTG045I', 'CCT_050', 'CCT_055', 'CCT_065B', 'CCT_065C', 'CCT_065D', 'CCT_065G', 'CCTG065I', 'CCT_070', 'CCT_075', 'CCT_080', 'DOCMH', 'CMH_005', 'CMHG010', 'CMH_015A', 'CMH_015B', 'CMH_015C', 'CMH_015D', 'CMH_015E', 'CMH_015F', 'DOSWL', 'SWL_005', 'SWL_010', 'SWL_015', 'SWL_020', 'SWL_025', 'SWL_030', 'SWL_035', 'SWL_040', 'SWL_045', 'DODEP', 'DEPDVPHQ', 'DEPDVSEV', 'DOSUI', 'SUI_005', 'SUI_010', 'DOSPS', 'SPS_015', 'SPS_020', 'SPS_025', 'SPS_035', 'SPS_050', 'DOPHC', 'PHC_005', 'PHC_010', 'PHC_015', 'PHC_020', 'PHC_025A', 'PHC_025B', 'PHC_025C', 'PHC_025D', 'PHC_025E', 'PHC_025F', 'PHC_030', 'PHC_035', 'PHC_045', 'PHC_050', 'PHC_055A', 'PHC_055B', 'PHC_055C', 'PHC_055D', 'PHC_055E', 'PHC_055F', 'PHC_055G', 'PHC_055H', 'PHC_055I', 'PHC_055J', 'PHC_055K', 'PHC_060', 'DOMDA', 'MDA_005', 'MDA_010', 'MDA_015', 'MDA_020', 'DOCP2', 'CP2_005', 'CP2G010', 'CP2_015', 'CP2G020', 'CP2_025', 'CP2G030', 'CP2_035', 'CP2G040', 'CP2_045', 'CP2G050', 'CP2_055', 'CP2G060', 'CP2_065', 'CP2G070', 'DOCP3', 'CP3_005', 'CP3G010', 'DOPNC', 'PNC_01A', 'PNC_01B', 'PNC_01C', 'PNC_01D', 'PNC_01E', 'PNC_02A', 'PNC_02BA', 'PNC_02BB', 'PNC_02BC', 'PNC_02BD', 'PN1_01A1', 'PN1_01B1', 'PN1_01C1', 'PN1_01D1', 'PN1_01E1', 'PN1_01F1', 'PN1_01G1', 'PN1_01H1', 'PN1_01I1', 'PN1_01K1', 'PN1G01L1', 'PN1_02A1', 'PN1_01A2', 'PN1_01B2', 'PN1_01C2', 'PN1_01D2', 'PN1_01E2', 'PN1_01F2', 'PN1_01G2', 'PN1_01H2', 'PN1_01I2', 'PN1_01K2', 'PN1G01L2', 'PN1_02A2', 'PN1_01A3', 'PN1_01B3', 'PN1_01C3', 'PN1_01D3', 'PN1_01E3', 'PN1_01F3', 'PN1_01G3', 'PN1_01H3', 'PN1_01I3', 'PN1_01K3', 'PN1G01L3', 'PN1_02A3', 'PN1_01A4', 'PN1_01B4', 'PN1_01C4', 'PN1_01D4', 'PN1_01E4', 'PN1_01F4', 'PN1_01G4', 'PN1_01H4', 'PN1_01I4', 'PN1_01K4', 'PN1G01L4', 'PN1_02A4', 'PNC_04A', 'PNC_04BA', 'PNC_04BB', 'PNC_04BC', 'PN1_01A5', 'PN1_01B5', 'PN1_01C5', 'PN1_01D5', 'PN1_01E5', 'PN1_01F5', 'PN1_01G5', 'PN1_01H5', 'PN1_01I5', 'PN1_01K5', 'PN1G01L5', 'PN1_02A5', 'PN1_01A6', 'PN1_01B6', 'PN1_01C6', 'PN1_01D6', 'PN1_01E6', 'PN1_01F6', 'PN1_01G6', 'PN1_01H6', 'PN1_01I6', 'PN1_01K6', 'PN1G01L6', 'PN1_02A6', 'PN1_01A7', 'PN1_01B7', 'PN1_01C7', 'PN1_01D7', 'PN1_01E7', 'PN1_01F7', 'PN1_01G7', 'PN1_01H7', 'PN1_01I7', 'PN1_01K7', 'PN1G01L7', 'PN1_02A7', 'PNCDVH12', 'PNCDVHCT', 'PNCDVPNI', 'PNCDVPNM', 'PNCDVPNC', 'PNCDVPNO', 'PNCDVNED', 'DOPSC', 'PSC_005', 'PSCG010', 'PSCG015', 'PSC_065', 'PSCG070', 'PSC_075', 'DOPEX', 'PEX_005', 'PEX_010', 'PEX_015', 'PEX_020', 'PEX_025', 'PEX_030', 'PEX_035', 'PEX_040', 'PEX_045', 'PEX_050', 'PEX_055', 'PEX_060', 'PEX_065', 'PEX_070', 'PEX_075', 'PEX_080', 'PEX_085', 'PEX_090', 'DOUCN', 'UCN_005', 'UCN_010A', 'UCN_010B', 'UCN_010C', 'UCN_010D', 'UCN_010E', 'UCN_010F', 'UCN_010G', 'UCN_010H', 'UCN_010I', 'UCN_010J', 'UCN_010K', 'UCN_015A', 'UCN_015B', 'UCN_015C', 'UCN_015D', 'UCN_015E', 'UCN_015F', 'UCN_015G', 'UCN_015H', 'UCN_015I', 'UCN_015J', 'UCN_020', 'UCN_025A', 'UCN_025B', 'UCN_025C', 'UCN_025D', 'UCN_025E', 'UCN_025F', 'LBFDGWSS', 'LBFDGHPW', 'LBFDVPFT', 'DOSDC', 'SDC_015', 'SDCDGCB', 'SDCDVIMM', 'SDCDVFLA', 'DOPMK', 'PMKPROXY', 'DOINS', 'INS_005', 'INS_010A', 'INS_010B', 'INS_010C', 'INS_010D', 'INS_015', 'INS_020A', 'INS_020B', 'INS_020C', 'INS_020D', 'DOFSC', 'FSCDVAF2', 'FSCDVCF2', 'FSCDVHF2', 'INCG015', 'INCDGHH', 'INCDGRCA', 'INCDGRPR', 'INCDGRRS', 'ADM_040', 'ADM_045', 'ADM_050', 'WTS_M']\n\n\nThe data consists of 108,252 rows and 691 columns.\n\n\nSelect rows that have information about diabetes\nCodes 9, 7, and 8 are for either refusing to disclose diabetes status, or not knowing or not stated.\n\ndf[[\"CCC_095\"]].value_counts()\n\nCCC_095\n2.0        95749\n1.0         9838\n9.0         2529\n7.0          112\n8.0           24\nName: count, dtype: int64\n\n\n\n#df[]\ndf = df[df[\"CCC_095\"].isin([1.0, 2.0])]\nprint(df[\"CCC_095\"].value_counts())\n\nCCC_095\n2.0    95749\n1.0     9838\nName: count, dtype: int64\n\n\n\n\nSelect only adult population\nCode = 1 is for people aged younger than 18.\n\ndf = df[~(df[\"DHHGAGE\"] == 1)]\ndf[\"DHHGAGE\"].value_counts()\n\nDHHGAGE\n5.0    47149\n4.0    20597\n3.0    16340\n2.0    15067\nName: count, dtype: int64\n\n\n\n\nPlot diabetes prevalence by province/territory\n\nLook at diabetes prevalence by state for adults over the age of 18.\n\n\nimport matplotlib.pyplot as plt\n\ndf_subset = df[[\"GEOGPRV\",\"CCC_095\"]]\n\n\ngeo_mapping = dict([(\"NEWFOUNDLAND AND LABRADOR\", 10),\n(\"PRINCE EDWARD ISLAND\", 11),\n(\"NOVA SCOTIA\", 12),\n(\"NEW BRUNSWICK\", 13),\n(\"QUEBEC\", 24),\n(\"ONTARIO\", 35),\n(\"MANITOBA\" , 46),\n(\"SASKATCHEWAN\" ,47),\n(\"ALBERTA\", 48),\n(\"BRITISH COLUMBIA\" , 59),\n(\"YUKON/NORTHWEST/NUNAVUT TERRITORIES\",60)]\n )\ngeo_mapping_reverse = {v: k for k,v in geo_mapping.items()}\n\n\ngrouped = df_subset.groupby([\"GEOGPRV\"])[\"CCC_095\"]\ngrouped_df = grouped.value_counts()/grouped.size()*100\n\ngrouped_df = grouped_df.reset_index()\n#print(grouped_df.columns[2])\ngrouped_df = grouped_df.rename(columns = {grouped_df.columns[2]: \"percent_respondents\"})\n#print(grouped_df)\ngrouped_df[\"Name\"] = [geo_mapping_reverse[num] for num in grouped_df[\"GEOGPRV\"]]\n#print(grouped_df)\ndf_plot = grouped_df[grouped_df[\"CCC_095\"] == 1].sort_values(by =\"percent_respondents\")\n\nfig, ax = plt.subplots()\ndf_plot.plot.barh(y = \"percent_respondents\", x = \"Name\",ax = ax)\nax.set_xlabel(\"% of respondents with diabetes\")\nax.set_ylabel(\"Province/Territory\")\nax.legend(\"\")\n\n\n\n\n\n\n\n\n\n\nPlot diabetes prevalence on a map\n\nimport geopandas as gpd\ngdf = gpd.read_file(\"./data/lpr_000b16a_f/lpr_000b16a_f.shp\")\nmerged_df = gdf.merge(df_plot, left_on = pd.to_numeric(gdf[\"PRIDU\"]), right_on = \"GEOGPRV\", how = \"outer\")\n\n# Modify the values for Northwest Territories an Nunavut to same as Yukon, since all values are merged in the data\n\nterritory_value = merged_df[merged_df[\"PRIDU\"]==\"60\"][\"percent_respondents\"].values[0]\nmerged_df.loc[merged_df[\"PRIDU\"].isin([\"61\", \"62\"]),\"percent_respondents\"] = territory_value\n\nmerged_df\n\nfig, ax = plt.subplots(figsize=(12, 8))\nmerged_df.plot(column='percent_respondents', legend=True, cmap='bwr', ax = ax)\nax.set_title('Percentage of survey respondents with diabetes')\nax.set_axis_off()\n\nfig_from_ax = ax.get_figure()\nfig_from_ax.savefig(\"diabetes_prevalence_canada.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Home",
    "section": "",
    "text": "A discussion with Cyclica, Altis Labs, Elucidata, and Atomwise on how to run successful machine learning projects in biotech and pharma R&D."
  },
  {
    "objectID": "talks.html#panel-discussion-implementing-ml-in-biopharma-rd",
    "href": "talks.html#panel-discussion-implementing-ml-in-biopharma-rd",
    "title": "Home",
    "section": "",
    "text": "A discussion with Cyclica, Altis Labs, Elucidata, and Atomwise on how to run successful machine learning projects in biotech and pharma R&D."
  },
  {
    "objectID": "talks.html#framework-for-quality-of-high-dimensional-biological-data",
    "href": "talks.html#framework-for-quality-of-high-dimensional-biological-data",
    "title": "Home",
    "section": "Framework for quality of high-dimensional biological data",
    "text": "Framework for quality of high-dimensional biological data\n\n\n\n\n Presentation at Elucidata’s User Group Meeting on how our team evaluates and measures data quality while making high-dimensional biological data Findable, Accessible, Interoperable, and Reusable (FAIR)."
  },
  {
    "objectID": "talks.html#role-of-data-curation-with-ontologies-in-biopharma-rd",
    "href": "talks.html#role-of-data-curation-with-ontologies-in-biopharma-rd",
    "title": "Home",
    "section": "Role of data-curation with ontologies in biopharma R&D",
    "text": "Role of data-curation with ontologies in biopharma R&D\n\n\n\n\n Talk with Pistoia Alliance, a non-profit alliance working to increase pre-competitive collaboration in life sciences industry. The talk highlights the role of data curation through ontologies to make data FAIR and to accelerate research."
  },
  {
    "objectID": "talks.html#product-release-curated-multi-omics-data-atlas",
    "href": "talks.html#product-release-curated-multi-omics-data-atlas",
    "title": "Home",
    "section": "Product release: Curated multi-omics data atlas",
    "text": "Product release: Curated multi-omics data atlas\n\n\n\n\n Product release for Elucidata’s Liver OmixAtlas, the largest repository of ML-ready liver tissue-derived biological datasets. The goal is to provide a curated data source of scRNA-seq, RNA-seq, proteomics, and metabolomics data to accelerate drug discovery."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Shefali Lathwal",
    "section": "",
    "text": "Data science leader with a Ph.D. and 6 years’ experience at an early-stage startup.\nFind out more on my About page.\n\n  \n\n\n\n\nRecent Blog Posts\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\n\n\nDiabetes prevalence in Community Health Survey Data 2019-2020 in Canada\n\n\nMay 13, 2025\n\n\n\n\n\n\n\nChance, p-values, and number of samples\n\n\nApr 17, 2025\n\n\n\n\n\n\n\nPermutation test in statistics\n\n\nMar 27, 2025\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\n\nProjects and Talks\n\nFind out more about my public projects.\nListen to my public talks.\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Shefali Lathwal",
    "section": "Experience",
    "text": "Experience\nElucidata Corporation | Director, data-centric AI\nJan 2022 - Oct 2022\nElucidata Corporation | Lead Scientist\nDec 2016 - Dec 2021"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Shefali Lathwal",
    "section": "Education",
    "text": "Education\nMassachusetts Institute of Technology\nCambridge, MA, USA\nPh.D. in Chemical Engineering\nM.S. in Chemical Engineering Practice\nIndian Institute of Technology, Delhi\nNew Delhi, India\nM.S. in Process Engineering and Design\nB.Tech. In Chemical Engineering"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Shefali Lathwal",
    "section": "",
    "text": "I have translated my background in mathematics, statistics, machine learning, engineering, and scientific experimentation into building data-driven solutions in the tech industry. I am a problem solver and enjoy building relationships with people, working in cross-functional teams, and translating complex data into actionable insights."
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Shefali Lathwal",
    "section": "Experience",
    "text": "Experience\nElucidata Corporation | Director, data-centric AI\nJan 2022 - Oct 2022\nElucidata Corporation | Lead Scientist\nDec 2016 - Dec 2021"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Shefali Lathwal",
    "section": "Education",
    "text": "Education\nMassachusetts Institute of Technology\nCambridge, MA, USA\nPh.D. in Chemical Engineering\nM.S. in Chemical Engineering Practice\nIndian Institute of Technology, Delhi\nNew Delhi, India\nM.S. in Process Engineering and Design\nB.Tech. In Chemical Engineering"
  },
  {
    "objectID": "index.html#blog-section",
    "href": "index.html#blog-section",
    "title": "Shefali Lathwal",
    "section": "Blog Section",
    "text": "Blog Section\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMay 13, 2025\n\n\nDiabetes prevalence in Community Health Survey Data 2019-2020 in Canada\n\n\nShefali Lathwal\n\n\n\n\nApr 17, 2025\n\n\nChance, p-values, and number of samples\n\n\nShefali Lathwal\n\n\n\n\nMar 27, 2025\n\n\nPermutation test in statistics\n\n\nShefali Lathwal\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#recent-blog-posts",
    "href": "index.html#recent-blog-posts",
    "title": "Shefali Lathwal",
    "section": "Recent Blog Posts",
    "text": "Recent Blog Posts\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitle\n\n\nDate\n\n\n\n\n\n\n\n\nDiabetes prevalence in Community Health Survey Data 2019-2020 in Canada\n\n\nMay 13, 2025\n\n\n\n\n\n\n\nChance, p-values, and number of samples\n\n\nApr 17, 2025\n\n\n\n\n\n\n\nPermutation test in statistics\n\n\nMar 27, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  }
]